"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[6413],{6898:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"part1/course_overview","title":"Course Overview","description":"Course Details","source":"@site/docs/part1/course_overview.md","sourceDirName":"part1","slug":"/part1/course_overview","permalink":"/hakathon-1/docs/part1/course_overview","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-humanoid-book/physical-ai-humanoid-book/tree/main/docs/part1/course_overview.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Course Overview"}}');var o=i(4848),t=i(8453);const a={sidebar_position:2,title:"Course Overview"},r="Course Overview: Physical AI & Humanoid Robotics",l={},d=[{value:"Course Details",id:"course-details",level:2},{value:"Quarter Overview",id:"quarter-overview",level:3},{value:"Module 1: The Robotic Nervous System (ROS 2)",id:"module-1-the-robotic-nervous-system-ros-2",level:3},{value:"Module 2: The Digital Twin (Gazebo &amp; Unity)",id:"module-2-the-digital-twin-gazebo--unity",level:3},{value:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)",id:"module-3-the-ai-robot-brain-nvidia-isaac",level:3},{value:"Module 4: Vision-Language-Action (VLA)",id:"module-4-vision-language-action-vla",level:3},{value:"Why Physical AI Matters",id:"why-physical-ai-matters",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Weekly Breakdown",id:"weekly-breakdown",level:2},{value:"Assessments",id:"assessments",level:2}];function c(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"course-overview-physical-ai--humanoid-robotics",children:"Course Overview: Physical AI & Humanoid Robotics"})}),"\n",(0,o.jsx)(n.h2,{id:"course-details",children:"Course Details"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Physical AI & Humanoid Robotics"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Focus and Theme:"})," AI Systems in the Physical World. Embodied Intelligence."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Goal:"})," Bridging the gap between the digital brain and the physical body. Students apply their AI knowledge to control Humanoid Robots in simulated and real-world environments."]}),"\n",(0,o.jsx)(n.h3,{id:"quarter-overview",children:"Quarter Overview"}),"\n",(0,o.jsx)(n.p,{children:"The future of AI extends beyond digital spaces into the physical world. This capstone quarter introduces Physical AI\u2014AI systems that function in reality and comprehend physical laws. Students learn to design, simulate, and deploy humanoid robots capable of natural human interactions using ROS 2, Gazebo, and NVIDIA Isaac."}),"\n",(0,o.jsx)(n.h3,{id:"module-1-the-robotic-nervous-system-ros-2",children:"Module 1: The Robotic Nervous System (ROS 2)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Focus:"})," Middleware for robot control."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"ROS 2 Nodes, Topics, and Services."}),"\n",(0,o.jsx)(n.li,{children:"Bridging Python Agents to ROS controllers using rclpy."}),"\n",(0,o.jsx)(n.li,{children:"Understanding URDF (Unified Robot Description Format) for humanoids."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"module-2-the-digital-twin-gazebo--unity",children:"Module 2: The Digital Twin (Gazebo & Unity)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Focus:"})," Physics simulation and environment building."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Simulating physics, gravity, and collisions in Gazebo."}),"\n",(0,o.jsx)(n.li,{children:"High-fidelity rendering and human-robot interaction in Unity."}),"\n",(0,o.jsx)(n.li,{children:"Simulating sensors: LiDAR, Depth Cameras, and IMUs."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"module-3-the-ai-robot-brain-nvidia-isaac",children:"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Focus:"})," Advanced perception and training."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"NVIDIA Isaac Sim: Photorealistic simulation and synthetic data generation."}),"\n",(0,o.jsx)(n.li,{children:"Isaac ROS: Hardware-accelerated VSLAM (Visual SLAM) and navigation."}),"\n",(0,o.jsx)(n.li,{children:"Nav2: Path planning for bipedal humanoid movement."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"module-4-vision-language-action-vla",children:"Module 4: Vision-Language-Action (VLA)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Focus:"})," The convergence of LLMs and Robotics."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Voice-to-Action: Using OpenAI Whisper for voice commands."}),"\n",(0,o.jsx)(n.li,{children:'Cognitive Planning: Using LLMs to translate natural language ("Clean the room") into a sequence of ROS 2 actions.'}),"\n",(0,o.jsx)(n.li,{children:"Capstone Project: The Autonomous Humanoid. A final project where a simulated robot receives a voice command, plans a path, navigates obstacles, identifies an object using computer vision, and manipulates it."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"why-physical-ai-matters",children:"Why Physical AI Matters"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots are poised to excel in our human-centered world because they share our physical form and can be trained with abundant data from interacting in human environments. This represents a significant transition from AI models confined to digital environments to embodied intelligence that operates in physical space."}),"\n",(0,o.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Understand Physical AI principles and embodied intelligence"}),"\n",(0,o.jsx)(n.li,{children:"Master ROS 2 (Robot Operating System) for robotic control"}),"\n",(0,o.jsx)(n.li,{children:"Simulate robots with Gazebo and Unity"}),"\n",(0,o.jsx)(n.li,{children:"Develop with NVIDIA Isaac AI robot platform"}),"\n",(0,o.jsx)(n.li,{children:"Design humanoid robots for natural interactions"}),"\n",(0,o.jsx)(n.li,{children:"Integrate GPT models for conversational robotics"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"weekly-breakdown",children:"Weekly Breakdown"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Weeks 1-2: Introduction to Physical AI"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Foundations of Physical AI and embodied intelligence"}),"\n",(0,o.jsx)(n.li,{children:"From digital AI to robots that understand physical laws"}),"\n",(0,o.jsx)(n.li,{children:"Overview of humanoid robotics landscape"}),"\n",(0,o.jsx)(n.li,{children:"Sensor systems: LIDAR, cameras, IMUs, force/torque sensors"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Weeks 3-5: ROS 2 Fundamentals"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"ROS 2 architecture and core concepts"}),"\n",(0,o.jsx)(n.li,{children:"Nodes, topics, services, and actions"}),"\n",(0,o.jsx)(n.li,{children:"Building ROS 2 packages with Python"}),"\n",(0,o.jsx)(n.li,{children:"Launch files and parameter management"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Weeks 6-7: Robot Simulation with Gazebo"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Gazebo simulation environment setup"}),"\n",(0,o.jsx)(n.li,{children:"URDF and SDF robot description formats"}),"\n",(0,o.jsx)(n.li,{children:"Physics simulation and sensor simulation"}),"\n",(0,o.jsx)(n.li,{children:"Introduction to Unity for robot visualization"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Weeks 8-10: NVIDIA Isaac Platform"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"NVIDIA Isaac SDK and Isaac Sim"}),"\n",(0,o.jsx)(n.li,{children:"AI-powered perception and manipulation"}),"\n",(0,o.jsx)(n.li,{children:"Reinforcement learning for robot control"}),"\n",(0,o.jsx)(n.li,{children:"Sim-to-real transfer techniques"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Weeks 11-12: Humanoid Robot Development"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Humanoid robot kinematics and dynamics"}),"\n",(0,o.jsx)(n.li,{children:"Bipedal locomotion and balance control"}),"\n",(0,o.jsx)(n.li,{children:"Manipulation and grasping with humanoid hands"}),"\n",(0,o.jsx)(n.li,{children:"Natural human-robot interaction design"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Week 13: Conversational Robotics"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Integrating GPT models for conversational AI in robots"}),"\n",(0,o.jsx)(n.li,{children:"Speech recognition and natural language understanding"}),"\n",(0,o.jsx)(n.li,{children:"Multi-modal interaction: speech, gesture, vision"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"assessments",children:"Assessments"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"ROS 2 package development project"}),"\n",(0,o.jsx)(n.li,{children:"Gazebo simulation implementation"}),"\n",(0,o.jsx)(n.li,{children:"Isaac-based perception pipeline"}),"\n",(0,o.jsx)(n.li,{children:"Capstone: Simulated humanoid robot with conversational AI"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>r});var s=i(6540);const o={},t=s.createContext(o);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);